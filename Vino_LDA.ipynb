{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from FE import FE\n",
    "from FE import text_process\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv('winemag-data-130k-v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling a list of wine varieties to filter the dataframe by\n",
    "keepers = list(wine.variety.value_counts()[wine.variety.value_counts() >= 1000].index)\n",
    "# filtering the dataframe\n",
    "filtered_wine = wine[wine.variety.isin(keepers)].copy(deep=True).reset_index()\n",
    "# wine color feature\n",
    "filtered_wine = FE(filtered_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_wine['variety'] = filtered_wine['variety'].str.replace('(\\s|-)','_').str.lower()\n",
    "processed_wine = text_process(filtered_wine, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = processed_wine['variety']\n",
    "X = processed_wine.drop(columns=['id','index','country','description','points','price','province','region_1',\n",
    "                                 'region_2','variety', 'country', 'taster_name', 'taster_twitter_handle', \n",
    "                                 'title', 'winery', 'year', 'continent', 'category', 'score_descriptive','designation'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Latent Dirichlet Allocation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_components = 28\n",
    "n_top_words = 20\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib_file = \"lda_model.pkl\"\n",
    "\n",
    "tf_train = X_train.drop(columns = ['x0_red','x0_rose', 'x0_unknown', 'x0_white'])\n",
    "\n",
    "# lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
    "#                                 learning_method='online',\n",
    "#                                 learning_offset=50.,\n",
    "#                                 random_state=0)\n",
    "# lda.fit(tf_train)\n",
    "\n",
    "# joblib.dump(lda, joblib_file)\n",
    "\n",
    "# instead of retraining lda model\n",
    "    \n",
    "lda = joblib.load(joblib_file)\n",
    "    \n",
    "tf_feature_names = X_train.columns[0:-4]\n",
    "tbl = pd.DataFrame(lda.transform(tf_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 28\n",
    "tbl = pd.DataFrame(lda.transform(tf_train))\n",
    "tbl.columns = ['topic_' + str(x) for x in range(n_components)]\n",
    "new_train = pd.concat([X_train[['x0_red','x0_rose', 'x0_unknown', 'x0_white']].reset_index(drop=True), \n",
    "                       tbl.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = pd.DataFrame(lda.transform(X_test.drop(columns=['x0_red','x0_rose', 'x0_unknown', 'x0_white'])))\n",
    "new_test.columns = ['topic_' + str(x) for x in range(n_components)]\n",
    "new_test = pd.concat([X_test[['x0_red','x0_rose', 'x0_unknown', 'x0_white']].reset_index(drop=True), \n",
    "                      new_test.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classification on LDA Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['forest_model.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_filename = 'forest_model.pkl'\n",
    "\n",
    "# gridsearch_forest = RandomForestClassifier()\n",
    "\n",
    "# params = {\n",
    "#     \"n_estimators\": [100, 300, 500],\n",
    "#     \"max_depth\": [5,15,25],\n",
    "#     \"min_samples_leaf\" : [1, 2, 4]\n",
    "# }\n",
    "\n",
    "# clf = RandomizedSearchCV(gridsearch_forest, param_distributions=params, cv=3 )\n",
    "# clf.fit(new_train,y_train)\n",
    "\n",
    "# joblib.dump(clf, forest_filename, compress=True)\n",
    "\n",
    "# instead of retraining random forest model\n",
    "\n",
    "clf = joblib.load(forest_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pred = clf.predict(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            precision    recall  f1-score   support\n",
      "\n",
      "  bordeaux_style_red_blend       0.48      0.61      0.54      2345\n",
      "bordeaux_style_white_blend       0.42      0.15      0.22       339\n",
      "            cabernet_franc       0.71      0.07      0.13       452\n",
      "        cabernet_sauvignon       0.34      0.55      0.42      3101\n",
      "           champagne_blend       0.56      0.36      0.44       437\n",
      "                chardonnay       0.52      0.87      0.65      3836\n",
      "                     gamay       0.38      0.13      0.20       319\n",
      "            gewürztraminer       0.66      0.11      0.19       344\n",
      "          grüner_veltliner       0.59      0.22      0.32       419\n",
      "                    malbec       0.38      0.13      0.19       864\n",
      "                    merlot       0.41      0.11      0.17       997\n",
      "                  nebbiolo       0.45      0.39      0.42       942\n",
      "              pinot_grigio       0.55      0.27      0.36       358\n",
      "                pinot_gris       0.71      0.69      0.70       506\n",
      "                pinot_noir       0.51      0.66      0.58      4402\n",
      "            portuguese_red       0.40      0.27      0.33       826\n",
      "          portuguese_white       0.47      0.16      0.24       404\n",
      "                 red_blend       0.38      0.51      0.44      2966\n",
      "     rhône_style_red_blend       0.71      0.28      0.40       484\n",
      "                  riesling       0.57      0.61      0.59      1727\n",
      "                      rosé       1.00      1.00      1.00      1163\n",
      "                sangiovese       0.49      0.18      0.27       925\n",
      "           sauvignon_blanc       0.62      0.33      0.43      1660\n",
      "           sparkling_blend       1.00      1.00      1.00       678\n",
      "                     syrah       0.44      0.16      0.23      1313\n",
      "               tempranillo       0.43      0.15      0.23       615\n",
      "               white_blend       0.59      0.20      0.30       777\n",
      "                 zinfandel       0.49      0.28      0.36       898\n",
      "\n",
      "                  accuracy                           0.50     34097\n",
      "                 macro avg       0.55      0.37      0.40     34097\n",
      "              weighted avg       0.51      0.50      0.47     34097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, forest_pred, target_names=clf.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classification on LDA Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(new_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_pred = gnb.predict(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            precision    recall  f1-score   support\n",
      "\n",
      "  bordeaux_style_red_blend       0.21      0.19      0.20      2345\n",
      "bordeaux_style_white_blend       0.19      0.25      0.21       339\n",
      "            cabernet_franc       0.05      0.04      0.04       452\n",
      "        cabernet_sauvignon       0.29      0.18      0.22      3101\n",
      "           champagne_blend       0.36      0.34      0.35       437\n",
      "                chardonnay       0.62      0.44      0.51      3836\n",
      "                     gamay       0.10      0.62      0.17       319\n",
      "            gewürztraminer       0.11      0.18      0.14       344\n",
      "          grüner_veltliner       0.19      0.26      0.22       419\n",
      "                    malbec       0.08      0.06      0.07       864\n",
      "                    merlot       0.15      0.02      0.04       997\n",
      "                  nebbiolo       0.19      0.79      0.31       942\n",
      "              pinot_grigio       0.20      0.26      0.23       358\n",
      "                pinot_gris       0.45      0.76      0.57       506\n",
      "                pinot_noir       0.66      0.37      0.47      4402\n",
      "            portuguese_red       0.22      0.32      0.26       826\n",
      "          portuguese_white       0.19      0.75      0.30       404\n",
      "                 red_blend       0.36      0.14      0.20      2966\n",
      "     rhône_style_red_blend       0.23      0.17      0.20       484\n",
      "                  riesling       0.44      0.53      0.48      1727\n",
      "                      rosé       1.00      1.00      1.00      1163\n",
      "                sangiovese       0.10      0.08      0.09       925\n",
      "           sauvignon_blanc       0.45      0.26      0.33      1660\n",
      "           sparkling_blend       1.00      1.00      1.00       678\n",
      "                     syrah       0.18      0.12      0.15      1313\n",
      "               tempranillo       0.09      0.34      0.14       615\n",
      "               white_blend       0.32      0.20      0.25       777\n",
      "                 zinfandel       0.29      0.31      0.30       898\n",
      "\n",
      "                  accuracy                           0.33     34097\n",
      "                 macro avg       0.31      0.36      0.30     34097\n",
      "              weighted avg       0.39      0.33      0.34     34097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, gnb_pred, target_names=gnb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
